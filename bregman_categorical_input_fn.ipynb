{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from datasets import flower_dataset\n",
    "#from models import models\n",
    "from backbone import inception\n",
    "from preprocessing import inception_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/dan/prj/datasets/flowers/flower_example1/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categorical_data(dataset_dir):\n",
    "  filepaths = {}\n",
    "  class_names = []\n",
    "  for dir_name in os.listdir(dataset_dir):\n",
    "    directory = os.path.join(dataset_dir, dir_name)\n",
    "    if os.path.isdir(directory):\n",
    "        filepaths[dir_name] = []\n",
    "        for filename in os.listdir(directory):\n",
    "            path = os.path.join(directory, filename)\n",
    "            filepaths[dir_name].append(path)\n",
    "        class_names.append(dir_name)\n",
    "  class_names_to_ids = dict(zip(class_names, range(len(class_names))))\n",
    "  return filepaths, class_names_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, label=None):\n",
    "  image_string = tf.read_file(filename)\n",
    "  image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "  # image_resized = tf.image.resize_images(image_decoded, [224, 224], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  images = inception_preprocessing.preprocess_image(\n",
    "      image_decoded, height=224, width=224, is_training=True)\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_input_fn(filepaths, class_names_to_ids, categorical_batch_size, num_images, mode=\"training\"):\n",
    "    data = {}\n",
    "    for name in class_names_to_ids.keys():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(tf.cast(\n",
    "            filepaths[name], tf.string))\n",
    "        dataset = dataset.shuffle(len(filepaths[name]))\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.map(_parse_function, num_parallel_calls=2)\n",
    "        dataset = dataset.batch(categorical_batch_size)\n",
    "        dataset = dataset.prefetch(2 * batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        data[name] = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths, class_names_to_ids = load_categorical_data(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for name in class_names_to_ids.keys():\n",
    "    dataset_filepath = tf.data.Dataset.from_tensor_slices(tf.cast(\n",
    "        filepaths[name], tf.string))\n",
    "    dataset_class = tf.data.Dataset.from_tensor_slices(\n",
    "        [class_names_to_ids[os.path.basename(os.path.dirname(filepath))] for filepath in filepaths[name]])\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((dataset_filepath, dataset_class))\n",
    "    dataset = dataset.shuffle(len(filepaths[name]))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=2)\n",
    "    dataset = dataset.batch(10)\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    data[name] = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = tf.stack([x for x in data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(stacked_data)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.70729524, -0.6758989 , -0.6131063 ],\n",
       "        [-0.7063145 , -0.6754788 , -0.61268616],\n",
       "        [-0.6966698 , -0.67134714, -0.6085545 ],\n",
       "        ...,\n",
       "        [ 0.6541207 ,  0.379403  ,  0.06310391],\n",
       "        [ 0.63521314,  0.31055105, -0.01387739],\n",
       "        [ 0.6104232 ,  0.23890042, -0.08552808]],\n",
       "\n",
       "       [[-0.7252032 , -0.6938069 , -0.6255013 ],\n",
       "        [-0.7242965 , -0.69316554, -0.62485987],\n",
       "        [-0.7153795 , -0.68685734, -0.6185517 ],\n",
       "        ...,\n",
       "        [ 0.66496634,  0.39812434,  0.05076528],\n",
       "        [ 0.6456529 ,  0.3238951 , -0.01650649],\n",
       "        [ 0.61868656,  0.24716365, -0.07726485]],\n",
       "\n",
       "       [[-0.7422709 , -0.71087456, -0.6370559 ],\n",
       "        [-0.7414532 , -0.71005684, -0.63623816],\n",
       "        [-0.7334112 , -0.70201486, -0.6281962 ],\n",
       "        ...,\n",
       "        [ 0.6721729 ,  0.41593993,  0.03849685],\n",
       "        [ 0.6528852 ,  0.3365996 , -0.01959735],\n",
       "        [ 0.62484896,  0.25500798, -0.0699811 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.5163887 , -0.45140022, -0.3737504 ],\n",
       "        [-0.5163212 , -0.4513327 , -0.37368286],\n",
       "        [-0.5156572 , -0.4506687 , -0.37301886],\n",
       "        ...,\n",
       "        [-0.5979494 , -0.6268228 , -0.69316626],\n",
       "        [-0.51741713, -0.5647097 , -0.64075977],\n",
       "        [-0.43677598, -0.5017645 , -0.58768386]],\n",
       "\n",
       "       [[-0.49986827, -0.4321233 , -0.3489604 ],\n",
       "        [-0.5002434 , -0.43249846, -0.34933555],\n",
       "        [-0.5039325 , -0.4361874 , -0.35302454],\n",
       "        ...,\n",
       "        [-0.64819336, -0.6770668 , -0.74892324],\n",
       "        [-0.5552661 , -0.6038631 , -0.6841218 ],\n",
       "        [-0.46156597, -0.52931094, -0.61798686]],\n",
       "\n",
       "       [[-0.49818844, -0.43016315, -0.34643966],\n",
       "        [-0.4986086 , -0.43058336, -0.3468598 ],\n",
       "        [-0.5027402 , -0.43471485, -0.35099143],\n",
       "        ...,\n",
       "        [-0.65330243, -0.68217576, -0.75459284],\n",
       "        [-0.55911475, -0.6078444 , -0.68853104],\n",
       "        [-0.4640867 , -0.53211206, -0.62106824]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = tf.stack([x[0] for x in data.values()])\n",
    "stacked_labels = tf.concat( [x[1] for x in data.values()], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.8474199  -0.80703104 -1.        ]\n",
      "  [-0.86209935 -0.8260087  -1.        ]\n",
      "  [-0.88148564 -0.8384036  -1.        ]\n",
      "  ...\n",
      "  [-0.96771044 -0.92796946 -1.        ]\n",
      "  [-0.96623504 -0.9246781  -1.        ]\n",
      "  [-0.9678534  -0.9205464  -1.        ]]\n",
      "\n",
      " [[-0.8644932  -0.8200213  -1.        ]\n",
      "  [-0.87618417 -0.83812785 -1.        ]\n",
      "  [-0.89615923 -0.855845   -1.        ]\n",
      "  ...\n",
      "  [-0.97789794 -0.94610673 -1.        ]\n",
      "  [-0.9735111  -0.93724823 -1.        ]\n",
      "  [-0.9703777  -0.9298252  -1.        ]]\n",
      "\n",
      " [[-0.8844193  -0.8384036  -1.        ]\n",
      "  [-0.895807   -0.8537004  -1.        ]\n",
      "  [-0.9134356  -0.8788098  -1.        ]\n",
      "  ...\n",
      "  [-0.98688555 -0.964244   -1.        ]\n",
      "  [-0.981043   -0.9506585  -1.        ]\n",
      "  [-0.9803248  -0.9478179  -1.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.88718927  0.3987813  -0.28085995]\n",
      "  [ 0.88750196  0.4058156  -0.28151286]\n",
      "  [ 0.8851888   0.41377413 -0.28282154]\n",
      "  ...\n",
      "  [-0.3548473  -0.5203469  -0.6289007 ]\n",
      "  [-0.34462976 -0.5184346  -0.61819863]\n",
      "  [-0.33809096 -0.51569885 -0.61113304]]\n",
      "\n",
      " [[ 0.8606138   0.38420177 -0.2986982 ]\n",
      "  [ 0.84443736  0.3830905  -0.31166863]\n",
      "  [ 0.84002554  0.38430452 -0.314623  ]\n",
      "  ...\n",
      "  [-0.347466   -0.50758916 -0.62072575]\n",
      "  [-0.3450675  -0.51200694 -0.6208206 ]\n",
      "  [-0.34288788 -0.5127982  -0.61977875]]\n",
      "\n",
      " [[ 0.82573974  0.37264562 -0.31958163]\n",
      "  [ 0.8095633   0.36512184 -0.3357582 ]\n",
      "  [ 0.80515146  0.3599236  -0.3401699 ]\n",
      "  ...\n",
      "  [-0.34092706 -0.49667823 -0.622931  ]\n",
      "  [-0.34288788 -0.50807846 -0.6221386 ]\n",
      "  [-0.34288788 -0.5127982  -0.61977875]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(stacked_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = tf.stack([x[0] for x in data.values()])\n",
    "#stacked_data = tf.reshape(stacked_data, shape=(-1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "x = sess.run(data['roses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(stacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['roses'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = [x for x in data.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stacked_data = tf.stack(stacked_data)\n",
    "new_real_stacked_data = tf.reshape(real_stacked_data, shape=(-1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(new_real_stacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    real_images = sess.run(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices( list(range(10)) )\n",
    "print(\"dataset1 : \")\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices( list(range(10)))\n",
    "\n",
    "print(\"dataset2 : \")\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)\n",
    "\n",
    "dataset3 = dataset1.concatenate(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [s1, s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[None, 224, 224, 3], dtype = tf.int32)\n",
    "y = tf.placeholder(shape=[None, 224, 224, 3], dtype = tf.int32)\n",
    "\n",
    "s = [x, y]\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tf.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
