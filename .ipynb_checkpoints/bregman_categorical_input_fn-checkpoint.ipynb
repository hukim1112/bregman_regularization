{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from datasets import flower_dataset\n",
    "#from models import models\n",
    "from backbone import inception\n",
    "from preprocessing import inception_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/dan/prj/datasets/flower_exp1/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categorical_data(dataset_dir):\n",
    "  filepaths = {}\n",
    "  class_names = []\n",
    "  for dir_name in os.listdir(dataset_dir):\n",
    "    directory = os.path.join(dataset_dir, dir_name)\n",
    "    if os.path.isdir(directory):\n",
    "        filepaths[dir_name] = []\n",
    "        for filename in os.listdir(directory):\n",
    "            path = os.path.join(directory, filename)\n",
    "            filepaths[dir_name].append(path)\n",
    "        class_names.append(dir_name)\n",
    "  class_names_to_ids = dict(zip(class_names, range(len(class_names))))\n",
    "  return filepaths, class_names_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, label=None):\n",
    "  image_string = tf.read_file(filename)\n",
    "  image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "  # image_resized = tf.image.resize_images(image_decoded, [224, 224], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  images = inception_preprocessing.preprocess_image(\n",
    "      image_decoded, height=224, width=224, is_training=True)\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_input_fn(filepaths, class_names_to_ids, categorical_batch_size, num_images, mode=\"training\"):\n",
    "    data = {}\n",
    "    for name in class_names_to_ids.keys():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(tf.cast(\n",
    "            filepaths[name], tf.string))\n",
    "        dataset = dataset.shuffle(len(filepaths[name]))\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.map(_parse_function, num_parallel_calls=2)\n",
    "        dataset = dataset.batch(categorical_batch_size)\n",
    "        dataset = dataset.prefetch(2 * batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        data[name] = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths, class_names_to_ids = load_categorical_data(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for name in class_names_to_ids.keys():\n",
    "    dataset_filepath = tf.data.Dataset.from_tensor_slices(tf.cast(\n",
    "        filepaths[name], tf.string))\n",
    "    dataset_class = tf.data.Dataset.from_tensor_slices(\n",
    "        [class_names_to_ids[os.path.basename(os.path.dirname(filepath))] for filepath in filepaths[name]])\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((dataset_filepath, dataset_class))\n",
    "    dataset = dataset.shuffle(len(filepaths[name]))\n",
    "    dataset = dataset.repeat()\n",
    "    #dataset = dataset.map(_parse_function, num_parallel_calls=2)\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    data[name] = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked_data = tf.stack([x for x in data.values()])\n",
    "#stacked_data = tf.reshape(stacked_data, shape=(-1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a list containing a tensor of dtype <dtype: 'int32'> to <dtype: 'string'> (Tensor is: <tf.Tensor 'IteratorGetNext_76:1' shape=(?,) dtype=int32>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-ef545b6edbee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstacked_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/p3tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m   \u001b[0mvalue_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvalue_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0mexpanded_num_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    969\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m    900\u001b[0m           raise TypeError(\"Cannot convert a list containing a tensor of dtype \"\n\u001b[1;32m    901\u001b[0m                           \"%s to %s (Tensor is: %r)\" % (elem.dtype, dtype,\n\u001b[0;32m--> 902\u001b[0;31m                                                         elem))\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0mconverted_elems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mmust_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a list containing a tensor of dtype <dtype: 'int32'> to <dtype: 'string'> (Tensor is: <tf.Tensor 'IteratorGetNext_76:1' shape=(?,) dtype=int32>)"
     ]
    }
   ],
   "source": [
    "stacked_data = tf.stack([x for x in data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "x = sess.run(data['roses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([b'/home/dan/prj/datasets/flower_exp1/train/roses/8209458141_38f38be65c_m.jpg'],\n",
       "       dtype=object), array([0], dtype=int32))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(stacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.6800072 , -0.8124637 , -0.9449202 ],\n",
       "         [-0.689391  , -0.79375964, -0.95593005],\n",
       "         [-0.7080185 , -0.78607315, -0.9812099 ],\n",
       "         ...,\n",
       "         [-0.6855675 , -0.61446077, -0.97339433],\n",
       "         [-0.71319807, -0.6519962 , -0.9914158 ],\n",
       "         [-0.73731124, -0.68322825, -1.        ]],\n",
       "\n",
       "        [[-0.6800072 , -0.8124637 , -0.9449202 ],\n",
       "         [-0.689391  , -0.79375964, -0.95593005],\n",
       "         [-0.7049372 , -0.7829919 , -0.9781286 ],\n",
       "         ...,\n",
       "         [-0.6654031 , -0.59089637, -0.9566736 ],\n",
       "         [-0.6979122 , -0.6284318 , -0.9743559 ],\n",
       "         [-0.7129092 , -0.65333325, -0.9927529 ]],\n",
       "\n",
       "        [[-0.6800072 , -0.8124637 , -0.9449202 ],\n",
       "         [-0.689391  , -0.79375964, -0.95593005],\n",
       "         [-0.7048547 , -0.7829965 , -0.9781042 ],\n",
       "         ...,\n",
       "         [-0.6574401 , -0.58297694, -0.9586154 ],\n",
       "         [-0.6899939 , -0.6204686 , -0.9665405 ],\n",
       "         [-0.6987469 , -0.63909703, -0.97854567]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3235991 , -0.03215575, -0.38824332],\n",
       "         [ 0.2719102 , -0.06236362, -0.42833406],\n",
       "         [ 0.19097233, -0.1203593 , -0.4896844 ],\n",
       "         ...,\n",
       "         [-0.40616548, -0.84322715, -0.9375147 ],\n",
       "         [-0.4151864 , -0.85215455, -0.946225  ],\n",
       "         [-0.43378854, -0.8509892 , -0.9153786 ]],\n",
       "\n",
       "        [[ 0.3394605 , -0.03292537, -0.3806975 ],\n",
       "         [ 0.28791988, -0.06625366, -0.42070723],\n",
       "         [ 0.20363367, -0.13407004, -0.48518407],\n",
       "         ...,\n",
       "         [-0.36524367, -0.81263614, -0.9134002 ],\n",
       "         [-0.40752602, -0.86414635, -0.9502578 ],\n",
       "         [-0.454054  , -0.8942351 , -0.9636709 ]],\n",
       "\n",
       "        [[ 0.34740865, -0.00864196, -0.35634023],\n",
       "         [ 0.29280055, -0.05007064, -0.39941746],\n",
       "         [ 0.19287074, -0.1138705 , -0.47630018],\n",
       "         ...,\n",
       "         [-0.41814315, -0.856944  , -0.91361356],\n",
       "         [-0.4319979 , -0.8758442 , -0.95216864],\n",
       "         [-0.41659105, -0.8636018 , -0.9595727 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([<tf.Tensor 'IteratorGetNext_36:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext_37:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext_38:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext_39:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext_40:0' shape=(?, 224, 224, 3) dtype=float32>])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(224), Dimension(224), Dimension(3)])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['roses'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = [x for x in data.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'IteratorGetNext_36:0' shape=(?, 224, 224, 3) dtype=float32>,\n",
       " <tf.Tensor 'IteratorGetNext_37:0' shape=(?, 224, 224, 3) dtype=float32>,\n",
       " <tf.Tensor 'IteratorGetNext_38:0' shape=(?, 224, 224, 3) dtype=float32>,\n",
       " <tf.Tensor 'IteratorGetNext_39:0' shape=(?, 224, 224, 3) dtype=float32>,\n",
       " <tf.Tensor 'IteratorGetNext_40:0' shape=(?, 224, 224, 3) dtype=float32>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reshape in module tensorflow.python.ops.gen_array_ops:\n",
      "\n",
      "reshape(tensor, shape, name=None)\n",
      "    Reshapes a tensor.\n",
      "    \n",
      "    Given `tensor`, this operation returns a tensor that has the same values\n",
      "    as `tensor` with shape `shape`.\n",
      "    \n",
      "    If one component of `shape` is the special value -1, the size of that dimension\n",
      "    is computed so that the total size remains constant.  In particular, a `shape`\n",
      "    of `[-1]` flattens into 1-D.  At most one component of `shape` can be -1.\n",
      "    \n",
      "    If `shape` is 1-D or higher, then the operation returns a tensor with shape\n",
      "    `shape` filled with the values of `tensor`. In this case, the number of elements\n",
      "    implied by `shape` must be the same as the number of elements in `tensor`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```\n",
      "    # tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "    # tensor 't' has shape [9]\n",
      "    reshape(t, [3, 3]) ==> [[1, 2, 3],\n",
      "                            [4, 5, 6],\n",
      "                            [7, 8, 9]]\n",
      "    \n",
      "    # tensor 't' is [[[1, 1], [2, 2]],\n",
      "    #                [[3, 3], [4, 4]]]\n",
      "    # tensor 't' has shape [2, 2, 2]\n",
      "    reshape(t, [2, 4]) ==> [[1, 1, 2, 2],\n",
      "                            [3, 3, 4, 4]]\n",
      "    \n",
      "    # tensor 't' is [[[1, 1, 1],\n",
      "    #                 [2, 2, 2]],\n",
      "    #                [[3, 3, 3],\n",
      "    #                 [4, 4, 4]],\n",
      "    #                [[5, 5, 5],\n",
      "    #                 [6, 6, 6]]]\n",
      "    # tensor 't' has shape [3, 2, 3]\n",
      "    # pass '[-1]' to flatten 't'\n",
      "    reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n",
      "    \n",
      "    # -1 can also be used to infer the shape\n",
      "    \n",
      "    # -1 is inferred to be 9:\n",
      "    reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                             [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
      "    # -1 is inferred to be 2:\n",
      "    reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                             [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
      "    # -1 is inferred to be 3:\n",
      "    reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],\n",
      "                                  [2, 2, 2],\n",
      "                                  [3, 3, 3]],\n",
      "                                 [[4, 4, 4],\n",
      "                                  [5, 5, 5],\n",
      "                                  [6, 6, 6]]]\n",
      "    \n",
      "    # tensor 't' is [7]\n",
      "    # shape `[]` reshapes to a scalar\n",
      "    reshape(t, []) ==> 7\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      tensor: A `Tensor`.\n",
      "      shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "        Defines the shape of the output tensor.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `tensor`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stacked_data = tf.stack(stacked_data)\n",
    "new_real_stacked_data = tf.reshape(real_stacked_data, shape=(-1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(new_real_stacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 224, 224, 3)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    real_images = sess.run(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1 : \n",
      "<dtype: 'int32'>\n",
      "()\n",
      "dataset2 : \n",
      "<dtype: 'int32'>\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices( list(range(10)) )\n",
    "print(\"dataset1 : \")\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices( list(range(10)))\n",
    "\n",
    "print(\"dataset2 : \")\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)\n",
    "\n",
    "dataset3 = dataset1.concatenate(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [s1, s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Const:0' shape=(3,) dtype=int32>,\n",
       " <tf.Tensor 'Const_1:0' shape=(3,) dtype=int32>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'Placeholder:0' shape=(?, 224, 224, 3) dtype=int32>, <tf.Tensor 'Placeholder_1:0' shape=(?, 224, 224, 3) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(shape=[None, 224, 224, 3], dtype = tf.int32)\n",
    "y = tf.placeholder(shape=[None, 224, 224, 3], dtype = tf.int32)\n",
    "\n",
    "s = [x, y]\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tf.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 224, 224, 3) dtype=int32>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3tf",
   "language": "python",
   "name": "p3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
